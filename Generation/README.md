# Condor production

To generate two-photons events use *condor_production.py* script. 
It will generate condor jobs to run all the steps of the simulation and the dumper. 


```
usage:condor_production.py [-h] --energy ENERGY [ENERGY ...] --eta ETA
                            [ETA ...] -n NEVENTS [-s SPLIT] -o OUTPUTDIR -c
                            CMSSW -q QUEUE [-e EOS] [--redo]

optional arguments:
  -h, --help            show this help message and exit
  --energy ENERGY [ENERGY ...]
                        energies
  --eta ETA [ETA ...]   etas
  -n NEVENTS, --nevents NEVENTS
                        N events for each configuration of eta and energy
  -s SPLIT, --split SPLIT
                        Divide N events in S jobs
  -o OUTPUTDIR, --outputdir OUTPUTDIR
                        Outputdir
  -c CMSSW, --cmssw CMSSW
                        Absolute path to CMSSW release
  -q QUEUE, --queue QUEUE
                        Condor queue
  -e EOS, --eos EOS     EOS instance user/cms
  --redo                Redo all files

```
Example:

```
python condor_production.py --energy 10. 50. 100. --eta 1.8 2.2 2.3  -o outputdir_on_eos -c /afs/cern.ch/work/d/dvalsecc/private/CMSSW_10_6_0 -q tomorrow -n 1000000 -s 100
Eta: 1.8 | R: 107.74344717871149 | Z: 317
Eta: 2.2 | R: 71.12239623501772 | Z: 317
Eta: 2.3 | R: 64.20953057483585 | Z: 317
Eta: 1.8 | R: 107.74344717871149 | Z: 317
Eta: 2.2 | R: 71.12239623501772 | Z: 317
Eta: 2.3 | R: 64.20953057483585 | Z: 317
Eta: 1.8 | R: 107.74344717871149 | Z: 317
Eta: 2.2 | R: 71.12239623501772 | Z: 317
Eta: 2.3 | R: 64.20953057483585 | Z: 317
Njobs:  90000
```
## Run only the dumper
To run the dumper on reco files (step3.root) from a previous production, use the script *condor_production_onlydumper.py*.

N.B.: this script expects the files in the format generated by the full production script. In particular it will run only on files ending with **_step3.root**. 

```
usage: condor_production_onlydumper.py [-h] -i INPUTDIR -o OUTPUTDIR -c CMSSW
                                       -q QUEUE [-e EOS] [--redo]

optional arguments:
  -h, --help            show this help message and exit
  -i INPUTDIR, --inputdir INPUTDIR
                        Inputdir
  -o OUTPUTDIR, --outputdir OUTPUTDIR
                        Outputdir
  -c CMSSW, --cmssw CMSSW
                        CMSSW tar
  -q QUEUE, --queue QUEUE
                        Condor queue
  -e EOS, --eos EOS     EOS instance user/cms
  --redo                Redo all files
```

## Overlap production
To produce a dataset for PfCluster overlap studies use the script *condor_production_overlap.py*.

```
usage: condor_production_overlap.py [-h] --energy ENERGY [ENERGY ...] --eta
                                    ETA [ETA ...] --energy2range ENERGY2RANGE
                                    [ENERGY2RANGE ...] --delta DELTA -n
                                    NEVENTS -o OUTPUTDIR -c CMSSW -q QUEUE
                                    [-e EOS] [--redo] [--repeat REPEAT]

optional arguments:
  -h, --help            show this help message and exit
  --energy ENERGY [ENERGY ...]
                        energies
  --eta ETA [ETA ...]   etas
  --energy2range ENERGY2RANGE [ENERGY2RANGE ...]
                        energies 2nd particle
  --delta DELTA         delta in cm
  -n NEVENTS, --nevents NEVENTS
                        n events
  -o OUTPUTDIR, --outputdir OUTPUTDIR
                        Outputdir
  -c CMSSW, --cmssw CMSSW
                        CMSSW tar
  -q QUEUE, --queue QUEUE
                        Condor queue
  -e EOS, --eos EOS     EOS instance user/cms
  --redo                Redo all files
  --repeat REPEAT       Repeat jobs for more events
```